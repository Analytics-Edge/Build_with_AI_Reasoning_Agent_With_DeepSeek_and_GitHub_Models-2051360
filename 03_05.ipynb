{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed4b608c-6700-48e3-ac03-b62480dc3954",
   "metadata": {},
   "source": [
    "Load testing is absolutely crucial for ensuring your DeepSeek reasoning agents can handle real-world traffic gracefully. Enter Locust—a fantastic Python-based load testing framework that simulates realistic user behavior and helps you understand exactly how your agents perform under pressure.\n",
    "\n",
    "Think of Locust as your AI agent's personal trainer. Just like athletes need to train under various conditions to perform their best, your reasoning agents need to be tested with different query types, traffic patterns, and stress levels to ensure they're ready for production deployment.\n",
    "\n",
    "Load testing reveals critical insights that you simply cannot discover through manual testing: How does response time change as concurrent users increase? At what point do error rates spike? How much will your API costs increase under real traffic loads? These questions are essential to answer before deploying your AI agent to real users.\n",
    "\n",
    "**Understanding Load Testing for AI Systems**\n",
    "\n",
    "Load testing AI systems differs significantly from testing traditional web applications. AI models have unique characteristics that affect performance under load:\n",
    "\n",
    "**Variable Processing Time**: Unlike static web pages, AI responses can take vastly different amounts of time depending on query complexity. A simple math question might respond in 200ms, while a complex reasoning task could take 10+ seconds.\n",
    "\n",
    "**Resource Intensive Operations**: AI inference uses substantial computational resources, and performance can degrade non-linearly as load increases.\n",
    "\n",
    "**Token-Based Costs**: Every request consumes tokens, so load testing also helps predict operational costs at scale.\n",
    "\n",
    "**Reasoning Complexity**: DeepSeek's reasoning capabilities add an extra layer of processing that traditional load tests don't account for.\n",
    "\n",
    "**Setting Up Locust for AI Load Testing**\n",
    "\n",
    "Let's start by installing and configuring Locust specifically for testing your DeepSeek reasoning agents.\n",
    "\n",
    "**Installing Locust**\n",
    "\n",
    "First, you'll need to install Locust in your development environment. Open your terminal or command prompt and run this command:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0b259f-2b35-4bf1-89de-24c853f07fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install locust\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32aa424f-acfd-48f0-a657-fdadf8205263",
   "metadata": {},
   "source": [
    "You'll see output showing the installation progress. Once complete, you can verify the installation by checking the version:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5a4465-1463-483f-9c10-c48a07fbe55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "locust \\--version\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925d4887-bc2b-47b8-a610-2c02721c0ddb",
   "metadata": {},
   "source": [
    "**Creating Your Load Test Configuration**\n",
    "\n",
    "Now you'll create a comprehensive load testing script that simulates realistic usage patterns for your DeepSeek reasoning agent. Create a new file called locustfile.py in your project directory.\n",
    "\n",
    "In this file, you'll define user behavior patterns that reflect how real users might interact with your AI agent:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63b45ce-b1a0-4dc0-8fce-ee91cfbbbdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from locust import HttpUser, task, between  \n",
    " import random  \n",
    " import json  \n",
    " import time  \n",
    " import os\n",
    "\n",
    " class ReasoningAgentUser(HttpUser):  \n",
    " \t\"\"\"  \n",
    " \tSimulates a user interacting with DeepSeek reasoning agents.  \n",
    " \tThis class defines realistic behavior patterns and query types.  \n",
    " \t\"\"\"  \n",
    " \t  \n",
    " \t\\# Wait between 2-8 seconds between requests (realistic user behavior)  \n",
    " \twait\\_time \\= between(2, 8\\)  \n",
    " \t  \n",
    " \tdef on\\_start(self):  \n",
    "     \t\"\"\"  \n",
    "     \tInitialize each simulated user with API credentials and query sets.  \n",
    "     \tThis runs once when each simulated user starts.  \n",
    "     \t\"\"\"  \n",
    "     \t  \n",
    "     \t\\# Set up authentication headers  \n",
    "     \t\\# Replace 'your\\_actual\\_api\\_key' with your real DeepSeek API key  \n",
    "     \tself.api\\_key \\= os.getenv(\"DEEPSEEK\\_API\\_KEY\") or \"your\\_actual\\_api\\_key\"  \n",
    "     \tself.headers \\= {  \n",
    "         \t\"Content-Type\": \"application/json\",  \n",
    "         \t\"Authorization\": f\"Bearer {self.api\\_key}\"  \n",
    "     \t}  \n",
    "     \t  \n",
    "     \t\\# Define different categories of queries to test various scenarios  \n",
    "     \tself.simple\\_queries \\= \\[  \n",
    "         \t\"What is 2+2?\",  \n",
    "         \t\"Define machine learning in one sentence.\",  \n",
    "         \t\"What is the capital of France?\",  \n",
    "         \t\"Convert 100 fahrenheit to celsius.\",  \n",
    "         \t\"What does API stand for?\",  \n",
    "         \t\"Name three primary colors.\",  \n",
    "         \t\"What is Python programming language?\",  \n",
    "         \t\"How many seconds in an hour?\"  \n",
    "     \t\\]  \n",
    "     \t  \n",
    "     \tself.medium\\_queries \\= \\[  \n",
    "         \t\"Explain the difference between machine learning and deep learning.\",  \n",
    "         \t\"What are the advantages and disadvantages of remote work?\",  \n",
    "         \t\"How does photosynthesis work?\",  \n",
    "         \t\"Describe the water cycle.\",  \n",
    "         \t\"What are the main causes of climate change?\",  \n",
    "         \t\"Explain how a computer processes information.\",  \n",
    "         \t\"What is the difference between SQL and NoSQL databases?\",  \n",
    "         \t\"How do search engines rank web pages?\"  \n",
    "     \t\\]  \n",
    "     \t  \n",
    "     \tself.complex\\_queries \\= \\[  \n",
    "         \t\"Analyze the trade-offs between different sorting algorithms and explain when to use each one.\",  \n",
    "         \t\"Design a system architecture for a real-time data processing platform that handles millions of events per second.\",  \n",
    "         \t\"Compare and contrast democratic and authoritarian governance systems, considering historical examples and modern implications.\",  \n",
    "         \t\"Explain the economic implications of artificial intelligence on employment, including both positive and negative effects with supporting evidence.\",  \n",
    "         \t\"Analyze the ethical considerations in genetic engineering, including benefits, risks, and regulatory frameworks.\",  \n",
    "         \t\"Design a comprehensive marketing strategy for a new sustainable energy product, including target audience analysis and competitive positioning.\"  \n",
    "     \t\\]  \n",
    "     \t  \n",
    "     \tself.reasoning\\_intensive\\_queries \\= \\[  \n",
    "         \t\"If a train leaves Station A at 2:00 PM traveling at 60 mph, and another train leaves Station B (120 miles away) at 2:30 PM traveling at 80 mph toward Station A, at what time and location will they meet? Show your reasoning step by step.\",  \n",
    "         \t\"A company's revenue was $100,000 in January. It increased by 15% in February, decreased by 8% in March, and increased by 22% in April. What was the revenue in April, and what was the overall percentage change from January to April? Explain your calculations.\",  \n",
    "         \t\"You have a 3-gallon jug and a 5-gallon jug. How can you measure exactly 4 gallons of water? Provide step-by-step reasoning for your solution.\",  \n",
    "         \t\"Three friends split a restaurant bill. Alice paid $30, Bob paid $25, and Charlie paid $20. They want to split it equally. Who owes money to whom, and how much? Show your reasoning process.\"  \n",
    "     \t\\]  \n",
    "     \t  \n",
    "     \t\\# Track this user's session for analytics  \n",
    "     \tself.user\\_session\\_id \\= f\"user\\_{random.randint(10000, 99999)}\\_{int(time.time())}\"  \n",
    "     \tprint(f\"🎯 Started load test user: {self.user\\_session\\_id}\")  \n",
    " \t  \n",
    " \tdef make\\_reasoning\\_request(self, query: str, max\\_tokens: int \\= 1000, reasoning\\_steps: bool \\= True):  \n",
    "     \t\"\"\"  \n",
    "     \tMake a request to the DeepSeek API with proper error handling and metrics collection.  \n",
    "     \t\"\"\"  \n",
    "     \t  \n",
    "     \tpayload \\= {  \n",
    "         \t\"model\": \"deepseek-reasoner\",  \n",
    "         \t\"messages\": \\[{\"role\": \"user\", \"content\": query}\\],  \n",
    "         \t\"max\\_tokens\": max\\_tokens,  \n",
    "         \t\"temperature\": 0.1,  \n",
    "         \t\"reasoning\\_steps\": reasoning\\_steps  \n",
    "     \t}  \n",
    "     \t  \n",
    "     \t\\# Record request details for debugging  \n",
    "     \trequest\\_start \\= time.time()  \n",
    "     \t  \n",
    "     \ttry:  \n",
    "         \t\\# Make the API call  \n",
    "         \twith self.client.post(  \n",
    "                 \"/v1/chat/completions\",  \n",
    "             \tjson=payload,  \n",
    "             \theaders=self.headers,  \n",
    "             \tcatch\\_response=True,  \n",
    "             \ttimeout=30  \\# 30 second timeout  \n",
    "         \t) as response:  \n",
    "             \t  \n",
    "             \trequest\\_time \\= time.time() \\- request\\_start  \n",
    "     \t          \n",
    "             \tif response.status\\_code \\== 200:  \n",
    "                 \t\\# Parse response to get token usage  \n",
    "                 \ttry:  \n",
    "                     \tresponse\\_data \\= response.json()  \n",
    "                     \ttokens\\_used \\= response\\_data.get('usage', {}).get('total\\_tokens', 0\\)  \n",
    "                     \t  \n",
    "                     \t\\# Log successful request details  \n",
    "                     \tprint(f\"✅ Query processed in {request\\_time:.2f}s, {tokens\\_used} tokens: {query\\[:50\\]}...\")  \n",
    "                     \t  \n",
    "                     \t\\# Mark as success in Locust  \n",
    "                         response.success()  \n",
    "                     \t  \n",
    "                 \texcept json.JSONDecodeError:  \n",
    "                     \tprint(f\"❌ Invalid JSON response for query: {query\\[:50\\]}...\")  \n",
    "                         response.failure(\"Invalid JSON response\")  \n",
    "                     \t  \n",
    "             \telif response.status\\_code \\== 429:  \n",
    "                 \t\\# Rate limiting \\- this is expected under high load  \n",
    "                 \tprint(f\"⚠️ Rate limited for query: {query\\[:50\\]}...\")  \n",
    "                     response.failure(\"Rate limited\")  \n",
    "                 \t  \n",
    "             \telif response.status\\_code \\== 401:  \n",
    "                 \tprint(f\"❌ Authentication failed \\- check API key\")  \n",
    "                     response.failure(\"Authentication failed\")  \n",
    "                 \t  \n",
    "             \telse:  \n",
    "                 \tprint(f\"❌ Request failed with status {response.status\\_code}: {query\\[:50\\]}...\")  \n",
    "                     response.failure(f\"HTTP {response.status\\_code}\")  \n",
    "                 \t  \n",
    "     \texcept Exception as e:  \n",
    "         \tprint(f\"❌ Request exception: {str(e)\\[:100\\]}...\")  \n",
    "         \t\\# Don't re-raise \\- let Locust handle the failure  \n",
    " \t  \n",
    " \t@task(50)  \\# 50% of requests are simple queries  \n",
    " \tdef simple\\_reasoning\\_task(self):  \n",
    "     \t\"\"\"  \n",
    "     \tTest simple queries that should respond quickly.  \n",
    "     \tThese represent basic user questions and quick lookups.  \n",
    "     \t\"\"\"  \n",
    "     \t  \n",
    "     \tquery \\= random.choice(self.simple\\_queries)  \n",
    "     \tprint(f\"🔹 Simple task: {query\\[:30\\]}...\")  \n",
    "     \t  \n",
    "     \tself.make\\_reasoning\\_request(  \n",
    "         \tquery=query,  \n",
    "         \tmax\\_tokens=500,  \n",
    "         \treasoning\\_steps=False  \\# Simple queries don't need reasoning steps  \n",
    "     \t)  \n",
    " \t  \n",
    " \t@task(30)  \\# 30% are medium complexity queries  \n",
    " \tdef medium\\_reasoning\\_task(self):  \n",
    "     \t\"\"\"  \n",
    "     \tTest medium complexity queries that require some explanation.  \n",
    "     \tThese represent typical user questions requiring detailed responses.  \n",
    "     \t\"\"\"  \n",
    "     \t  \n",
    "     \tquery \\= random.choice(self.medium\\_queries)  \n",
    "     \tprint(f\"🔸 Medium task: {query\\[:30\\]}...\")  \n",
    "     \t  \n",
    "     \tself.make\\_reasoning\\_request(  \n",
    "         \tquery=query,  \n",
    "         \tmax\\_tokens=1200,  \n",
    "         \treasoning\\_steps=True  \\# Show some reasoning for medium queries  \n",
    "     \t)  \n",
    " \t  \n",
    " \t@task(15)  \\# 15% are complex analytical queries  \n",
    " \tdef complex\\_reasoning\\_task(self):  \n",
    "     \t\"\"\"  \n",
    "     \tTest complex queries that require detailed analysis and reasoning.  \n",
    "     \tThese represent power users asking sophisticated questions.  \n",
    "     \t\"\"\"  \n",
    "     \t  \n",
    "     \tquery \\= random.choice(self.complex\\_queries)  \n",
    "     \tprint(f\"🔶 Complex task: {query\\[:30\\]}...\")  \n",
    "     \t  \n",
    "     \tself.make\\_reasoning\\_request(  \n",
    "         \tquery=query,  \n",
    "         \tmax\\_tokens=2500,  \n",
    "         \treasoning\\_steps=True  \\# Full reasoning for complex queries  \n",
    "     \t)  \n",
    " \t  \n",
    " \t@task(5)  \\# 5% are reasoning-intensive mathematical/logical problems  \n",
    " \tdef intensive\\_reasoning\\_task(self):  \n",
    "     \t\"\"\"  \n",
    "     \tTest the most demanding reasoning tasks.  \n",
    "     \tThese represent users asking for step-by-step problem solving.  \n",
    "     \t\"\"\"  \n",
    "     \t  \n",
    "     \tquery \\= random.choice(self.reasoning\\_intensive\\_queries)  \n",
    "     \tprint(f\"🔴 Intensive task: {query\\[:30\\]}...\")  \n",
    "     \t  \n",
    "     \tself.make\\_reasoning\\_request(  \n",
    "         \tquery=query,  \n",
    "         \tmax\\_tokens=3000,  \n",
    "         \treasoning\\_steps=True  \\# Maximum reasoning for intensive tasks  \n",
    "     \t)\n",
    "\n",
    " class QuickTestUser(HttpUser):  \n",
    " \t\"\"\"  \n",
    " \tA simpler user class for quick load tests and debugging.  \n",
    " \tUse this when you want to test basic functionality without complex scenarios.  \n",
    " \t\"\"\"  \n",
    " \t  \n",
    " \twait\\_time \\= between(1, 3\\)  \\# Faster requests for quick testing  \n",
    " \t  \n",
    " \tdef on\\_start(self):  \n",
    "         self.api\\_key \\= os.getenv(\"DEEPSEEK\\_API\\_KEY\") or \"your\\_actual\\_api\\_key\"  \n",
    "     \tself.headers \\= {  \n",
    "         \t\"Content-Type\": \"application/json\",  \n",
    "         \t\"Authorization\": f\"Bearer {self.api\\_key}\"  \n",
    "     \t}  \n",
    " \t  \n",
    " \t@task  \n",
    " \tdef quick\\_test(self):  \n",
    "     \t\"\"\"Simple test query for debugging and quick validation.\"\"\"  \n",
    "     \t  \n",
    "     \tpayload \\= {  \n",
    "         \t\"model\": \"deepseek-reasoner\",  \n",
    "         \t\"messages\": \\[{\"role\": \"user\", \"content\": \"What is 5 \\+ 3?\"}\\],  \n",
    "         \t\"max\\_tokens\": 100,  \n",
    "         \t\"temperature\": 0.1  \n",
    "     \t}  \n",
    "     \t  \n",
    "         self.client.post(\"/v1/chat/completions\", json=payload, headers=self.headers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03dce36a-f664-4db8-8208-fab19c013a47",
   "metadata": {},
   "source": [
    "This comprehensive load testing script provides several different user behavior patterns and query types that reflect realistic usage of your DeepSeek reasoning agent.\n",
    "\n",
    "**Running Your Load Tests**\n",
    "\n",
    "Now that you have your load testing script ready, let's run different test scenarios to understand your agent's performance characteristics.\n",
    "\n",
    "**Starting with Light Load Testing**\n",
    "\n",
    "Always start with light load to verify that your setup is working correctly before scaling up to heavier tests. Open your terminal and run this command:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d43ed4c-4b25-40fb-a210-5502fdab031d",
   "metadata": {},
   "outputs": [],
   "source": [
    "locust \\-f locustfile.py \\--host=https://api.deepseek.com \\--users=5 \\--spawn-rate=1 \\--run-time=2m \\--headless\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0d1a81-28e5-44ae-a033-08ca8c578c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Let's break down what each parameter does:\n",
    "\n",
    "·       \\-f locustfile.py: Specifies your test file\n",
    "\n",
    "·       \\--host=https://api.deepseek.com: The base URL for your API calls\n",
    "\n",
    "·       \\--users=5: Start with 5 simulated concurrent users\n",
    "\n",
    "·       \\--spawn-rate=1: Add 1 new user per second until reaching the target\n",
    "\n",
    "·       \\--run-time=2m: Run the test for 2 minutes\n",
    "\n",
    "·       \\--headless: Run without the web interface (results printed to console)\n",
    "\n",
    "You should see output like this in your terminal:\n",
    "\n",
    "\\[2025-08-08 15:16:12,345\\] Starting Locust 2.x.x  \n",
    " \\[2025-08-08 15:16:12,346\\] Spawning 5 users at the rate 1 users/s (0 users already running)...  \n",
    " ✅ Query processed in 1.23s, 45 tokens: What is 2+2?...  \n",
    " 🔹 Simple task: What is the capital of France...  \n",
    " ✅ Query processed in 0.89s, 32 tokens: What is the capital of France...\n",
    "\n",
    "**Interactive Load Testing with Web Interface**\n",
    "\n",
    "For more detailed monitoring and real-time control, run Locust with its web interface:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800bd167-7faf-4624-b7a0-127b605889f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "locust \\-f locustfile.py \\--host=https://api.deepseek.com\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faaf65d5-2fdd-493e-ae01-902e7e1ad2a4",
   "metadata": {},
   "source": [
    "After running this command, you'll see output indicating that Locust has started its web interface:\n",
    "\n",
    "\\[2025-08-08 15:16:12,345\\] Starting web interface at http://0.0.0.0:8089  \n",
    " \\[2025-08-08 15:16:12,346\\] Starting Locust 2.x.x\n",
    "\n",
    "Open your web browser and navigate to http://localhost:8089. You'll see the Locust web interface with several key sections:\n",
    "\n",
    "**Start New Test Section**: At the top of the page, you'll see input fields where you can specify:\n",
    "\n",
    "·       Number of users (total concurrent users to simulate)\n",
    "\n",
    "·       Spawn rate (users per second to add until reaching the target)\n",
    "\n",
    "·       Host (should show your API endpoint)\n",
    "\n",
    "**Statistics Table**: Once your test is running, you'll see a real-time table showing:\n",
    "\n",
    "·       Request types and URLs\n",
    "\n",
    "·       Number of requests made\n",
    "\n",
    "·       Number of failures\n",
    "\n",
    "·       Average response time\n",
    "\n",
    "·       Min/Max response times\n",
    "\n",
    "·       Requests per second\n",
    "\n",
    "**Charts Section**: Below the statistics, you'll find interactive charts showing:\n",
    "\n",
    "·       Response times over time\n",
    "\n",
    "·       Number of users over time\n",
    "\n",
    "·       Requests per second over time\n",
    "\n",
    "**Progressive Load Testing Strategy**\n",
    "\n",
    "Use this step-by-step approach to systematically understand your agent's performance:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dd3ea3-7325-4241-8ada-69bd91ba1f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\\# Step 1: Minimal load (verify functionality)  \n",
    " locust \\-f locustfile.py \\--host=https://api.deepseek.com \\--users=2 \\--spawn-rate=1 \\--run-time=1m \\--headless\n",
    "\n",
    " \\# Step 2: Light load (baseline performance)  \n",
    " locust \\-f locustfile.py \\--host=https://api.deepseek.com \\--users=10 \\--spawn-rate=2 \\--run-time=3m \\--headless\n",
    "\n",
    " \\# Step 3: Moderate load (typical usage)  \n",
    " locust \\-f locustfile.py \\--host=https://api.deepseek.com \\--users=25 \\--spawn-rate=5 \\--run-time=5m \\--headless\n",
    "\n",
    " \\# Step 4: Heavy load (peak traffic simulation)  \n",
    " locust \\-f locustfile.py \\--host=https://api.deepseek.com \\--users=50 \\--spawn-rate=5 \\--run-time=10m \\--headless\n",
    "\n",
    " \\# Step 5: Stress test (find breaking point)  \n",
    " locust \\-f locustfile.py \\--host=https://api.deepseek.com \\--users=100 \\--spawn-rate=10 \\--run-time=10m \\--headless"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ff5a82-67dc-49c6-8da1-337927f6b82d",
   "metadata": {},
   "source": [
    "Run each test level and record the results before moving to the next level. This progressive approach helps you identify exactly when performance starts to degrade.\n",
    "\n",
    "**Advanced Load Testing Scenarios**\n",
    "\n",
    "For production readiness, you'll want to test more sophisticated scenarios that reflect real-world usage patterns.\n",
    "\n",
    "**Creating Realistic User Sessions**\n",
    "\n",
    "Add this enhanced user class to your locustfile.py to simulate more realistic user behavior:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb70aaf-d2c0-4cf7-8040-af2f614082e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RealisticSessionUser(HttpUser):  \n",
    " \t\"\"\"  \n",
    " \tSimulates realistic user sessions with multiple related queries.  \n",
    " \tModels how real users might have conversations or work sessions with the AI.  \n",
    " \t\"\"\"  \n",
    " \t  \n",
    " \twait\\_time \\= between(3, 15\\)  \\# More realistic thinking time between queries  \n",
    " \t  \n",
    " \tdef on\\_start(self):  \n",
    "     \t\"\"\"Initialize user with session-based behavior patterns.\"\"\"  \n",
    "     \t  \n",
    "     \tself.api\\_key \\= os.getenv(\"DEEPSEEK\\_API\\_KEY\") or \"your\\_actual\\_api\\_key\"  \n",
    "     \tself.headers \\= {  \n",
    "         \t\"Content-Type\": \"application/json\",  \n",
    "         \t\"Authorization\": f\"Bearer {self.api\\_key}\"  \n",
    "     \t}  \n",
    "     \t  \n",
    "     \t\\# Define conversation themes that users might explore  \n",
    "     \tself.conversation\\_themes \\= {  \n",
    "         \t\"programming\": \\[  \n",
    "             \t\"What is Python programming language?\",  \n",
    "             \t\"How do I write a function in Python?\",  \n",
    "             \t\"What are the best practices for Python code?\",  \n",
    "             \t\"Explain object-oriented programming in Python.\",  \n",
    "             \t\"How do I handle errors in Python?\"  \n",
    "         \t\\],  \n",
    "             \"business\\_analysis\": \\[  \n",
    "             \t\"What is market research?\",  \n",
    "             \t\"How do I analyze competitor strategies?\",  \n",
    "             \t\"What are key performance indicators for business?\",  \n",
    "             \t\"Explain different pricing strategies.\",  \n",
    "             \t\"How do I create a business plan?\"  \n",
    "         \t\\],  \n",
    "         \t\"science\": \\[  \n",
    "             \t\"What is quantum physics?\",  \n",
    "             \t\"Explain the theory of relativity.\",  \n",
    "             \t\"How do black holes work?\",  \n",
    "             \t\"What is the difference between DNA and RNA?\",  \n",
    "             \t\"Explain photosynthesis in detail.\"  \n",
    "         \t\\]  \n",
    "     \t}  \n",
    "     \t  \n",
    "     \t\\# Each user picks a theme for their session  \n",
    "     \tself.current\\_theme \\= random.choice(list(self.conversation\\_themes.keys()))  \n",
    "     \tself.theme\\_queries \\= self.conversation\\_themes\\[self.current\\_theme\\].copy()  \n",
    "         random.shuffle(self.theme\\_queries)  \\# Randomize order  \n",
    "     \t  \n",
    "     \tself.session\\_query\\_count \\= 0  \n",
    "     \tself.max\\_session\\_queries \\= random.randint(3, 7\\)  \\# 3-7 queries per session  \n",
    "     \t  \n",
    "     \tprint(f\"👤 User session started with theme: {self.current\\_theme}\")  \n",
    " \t  \n",
    " \t@task  \n",
    " \tdef themed\\_conversation(self):  \n",
    "     \t\"\"\"  \n",
    "     \tSimulate a user having a themed conversation with the AI.  \n",
    "     \t\"\"\"  \n",
    "     \t  \n",
    "     \tif self.session\\_query\\_count \\>= self.max\\_session\\_queries:  \n",
    "         \t\\# End this user's session  \n",
    "         \tprint(f\"👤 User session completed ({self.session\\_query\\_count} queries)\")  \n",
    "         \tself.stop()  \n",
    "         \treturn  \n",
    "     \t  \n",
    "     \tif self.theme\\_queries:  \n",
    "         \tquery \\= self.theme\\_queries.pop(0)  \n",
    "     \telse:  \n",
    "         \t\\# If we run out of themed queries, ask follow-up questions  \n",
    "         \tquery \\= f\"Can you elaborate more on the previous topic?\"  \n",
    "     \t  \n",
    "     \tself.session\\_query\\_count \\+= 1  \n",
    "     \t  \n",
    "     \tprint(f\"🗣️ Session query {self.session\\_query\\_count}: {query\\[:40\\]}...\")  \n",
    "     \t  \n",
    "     \t\\# Adjust parameters based on session progress  \n",
    "     \t\\# Later queries in a session tend to be more specific/complex  \n",
    "     \tmax\\_tokens \\= 800 \\+ (self.session\\_query\\_count \\* 200\\)  \\# Gradually increase depth  \n",
    "     \treasoning\\_steps \\= self.session\\_query\\_count \\> 1  \\# Enable reasoning after first query  \n",
    "     \t  \n",
    "         self.make\\_reasoning\\_request(query, max\\_tokens, reasoning\\_steps)  \n",
    " \t  \n",
    " \tdef make\\_reasoning\\_request(self, query: str, max\\_tokens: int \\= 1000, reasoning\\_steps: bool \\= True):  \n",
    "     \t\"\"\"Make API request with session tracking.\"\"\"  \n",
    "     \t  \n",
    "     \tpayload \\= {  \n",
    "         \t\"model\": \"deepseek-reasoner\",  \n",
    "         \t\"messages\": \\[{\"role\": \"user\", \"content\": query}\\],  \n",
    "         \t\"max\\_tokens\": max\\_tokens,  \n",
    "         \t\"temperature\": 0.1,  \n",
    "         \t\"reasoning\\_steps\": reasoning\\_steps  \n",
    "     \t}  \n",
    "     \t  \n",
    "     \twith self.client.post(  \n",
    "             \"/v1/chat/completions\",  \n",
    "         \tjson=payload,  \n",
    "         \theaders=self.headers,  \n",
    "      \t   catch\\_response=True,  \n",
    "         \ttimeout=45  \\# Longer timeout for session-based queries  \n",
    "     \t) as response:  \n",
    "         \t  \n",
    "         \tif response.status\\_code \\== 200:  \n",
    "             \ttry:  \n",
    "                 \tresponse\\_data \\= response.json()  \n",
    "                 \ttokens\\_used \\= response\\_data.get('usage', {}).get('total\\_tokens', 0\\)  \n",
    "                 \tprint(f\"✅ Session query completed: {tokens\\_used} tokens\")  \n",
    "                 \tresponse.success()  \n",
    "             \texcept json.JSONDecodeError:  \n",
    "                     response.failure(\"Invalid JSON response\")  \n",
    "         \telse:  \n",
    "             \tprint(f\"❌ Session query failed: {response.status\\_code}\")  \n",
    "                 response.failure(f\"HTTP {response.status\\_code}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ce1842-c990-4f64-b2be-059c4ccf70d4",
   "metadata": {},
   "source": [
    "**Load Testing with Different Time Patterns**\n",
    "\n",
    "Create tests that simulate different traffic patterns throughout the day:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6480a0e4-c5da-43b1-852a-7ecd63b637eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeBasedUser(HttpUser):  \n",
    " \t\"\"\"  \n",
    " \tSimulates users with different behavior patterns based on time of day.  \n",
    " \tMorning users might ask different types of questions than evening users.  \n",
    " \t\"\"\"  \n",
    " \t  \n",
    " \tdef on\\_start(self):  \n",
    "     \tself.api\\_key \\= os.getenv(\"DEEPSEEK\\_API\\_KEY\") or \"your\\_actual\\_api\\_key\"  \n",
    "     \tself.headers \\= {  \n",
    "         \t\"Content-Type\": \"application/json\",  \n",
    "         \t\"Authorization\": f\"Bearer {self.api\\_key}\"  \n",
    "     \t}  \n",
    "     \t  \n",
    "     \t\\# Determine user type based on simulated time of day  \n",
    "     \thour \\= random.randint(6, 23\\)  \\# Simulate 6 AM to 11 PM  \n",
    "     \t  \n",
    "     \tif 6 \\<= hour \\<= 9:  \\# Morning users  \n",
    "         \tself.user\\_type \\= \"morning\\_commuter\"  \n",
    "         \tself.wait\\_time \\= between(1, 3\\)  \\# Quick queries  \n",
    "         \tself.query\\_pool \\= \\[  \n",
    "             \t\"What's the weather like today?\",  \n",
    "             \t\"Give me a quick summary of today's news.\",  \n",
    "             \t\"What's my schedule optimization tip for today?\"  \n",
    "         \t\\]  \n",
    "     \telif 9 \\<= hour \\<= 17:  \\# Business hours  \n",
    "         \tself.user\\_type \\= \"business\\_user\"  \n",
    "         \tself.wait\\_time \\= between(5, 20\\)  \\# Thoughtful queries  \n",
    "         \tself.query\\_pool \\= \\[  \n",
    "             \t\"Analyze this business proposal for potential risks.\",  \n",
    "             \t\"What are the latest trends in digital marketing?\",  \n",
    "             \t\"Help me write a professional email response.\"  \n",
    "         \t\\]  \n",
    "     \telse:  \\# Evening users  \n",
    "         \tself.user\\_type \\= \"evening\\_learner\"  \n",
    "         \tself.wait\\_time \\= between(10, 30\\)  \\# Deep learning sessions  \n",
    "         \tself.query\\_pool \\= \\[  \n",
    "             \t\"Explain quantum computing in detail.\",  \n",
    "             \t\"What are the philosophical implications of AI?\",  \n",
    "             \t\"Help me understand complex mathematical concepts.\"  \n",
    "         \t\\]  \n",
    "     \t  \n",
    "     \tprint(f\"🕐 {self.user\\_type} user active (simulated hour: {hour})\")  \n",
    " \t  \n",
    " \t@task  \n",
    " \tdef time\\_appropriate\\_query(self):  \n",
    "     \t\"\"\"Make queries appropriate for the user's time-based profile.\"\"\"  \n",
    "     \t  \n",
    "     \tquery \\= random.choice(self.query\\_pool)  \n",
    "     \t  \n",
    "     \t\\# Adjust request parameters based on user type  \n",
    "     \tif self.user\\_type \\== \"morning\\_commuter\":  \n",
    "         \tmax\\_tokens \\= 300  \\# Brief responses  \n",
    "         \treasoning\\_steps \\= False  \n",
    "     \telif self.user\\_type \\== \"business\\_user\":  \n",
    "         \tmax\\_tokens \\= 1500  \\# Professional depth  \n",
    "         \treasoning\\_steps \\= True  \n",
    "     \telse:  \\# evening\\_learner  \n",
    "         \tmax\\_tokens \\= 2500  \\# Deep explanations  \n",
    "         \treasoning\\_steps \\= True  \n",
    "     \t  \n",
    "         self.make\\_reasoning\\_request(query, max\\_tokens, reasoning\\_steps)  \n",
    " \t  \n",
    " \tdef make\\_reasoning\\_request(self, query: str, max\\_tokens: int, reasoning\\_steps: bool):  \n",
    "     \t\"\"\"Make request with user-type specific handling.\"\"\"  \n",
    "     \t  \n",
    "     \tpayload \\= {  \n",
    "         \t\"model\": \"deepseek-reasoner\",  \n",
    "         \t\"messages\": \\[{\"role\": \"user\", \"content\": query}\\],  \n",
    "         \t\"max\\_tokens\": max\\_tokens,  \n",
    "         \t\"temperature\": 0.1,  \n",
    "         \t\"reasoning\\_steps\": reasoning\\_steps  \n",
    "     \t}  \n",
    "     \t  \n",
    "         self.client.post(\"/v1/chat/completions\", json=payload, headers=self.headers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332d7854-917c-4471-8471-83e538fc3c97",
   "metadata": {},
   "source": [
    "**Analyzing Load Test Results**\n",
    "\n",
    "Understanding your load test results is crucial for making informed decisions about production deployment.\n",
    "\n",
    "**Key Metrics to Monitor**\n",
    "\n",
    "When analyzing your Locust results, focus on these critical metrics:\n",
    "\n",
    "**Response Time Percentiles**: Don't just look at averages. Check the 50th, 90th, and 95th percentiles:\n",
    "\n",
    "·       50th percentile: Half of your users experience this response time or better\n",
    "\n",
    "·       90th percentile: 90% of users experience this response time or better\n",
    "\n",
    "·       95th percentile: Your worst-case scenario for most users\n",
    "\n",
    "**Failure Rate**: Any failures indicate problems that need investigation:\n",
    "\n",
    "·       0-1%: Excellent\n",
    "\n",
    "·       1-5%: Acceptable for most applications\n",
    "\n",
    "·       Above 5%: Needs investigation and improvement\n",
    "\n",
    "**Requests Per Second (RPS)**: This shows your throughput capacity:\n",
    "\n",
    "·       Higher RPS with stable response times \\= better performance\n",
    "\n",
    "·       Declining RPS under load \\= system saturation\n",
    "\n",
    "**Resource Utilization**: Monitor what's causing performance limitations:\n",
    "\n",
    "·       High response times with low failure rates \\= processing bottleneck\n",
    "\n",
    "·       High failure rates \\= API rate limiting or server overload\n",
    "\n",
    "**Creating Custom Load Test Reports**\n",
    "\n",
    "Add this reporting functionality to your load testing setup:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326a1948-e812-400e-b980-05837c443e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv  \n",
    " from datetime import datetime\n",
    "\n",
    " class LoadTestReporter:  \n",
    " \t\"\"\"  \n",
    " \tCustom reporter for analyzing and documenting load test results.  \n",
    " \t\"\"\"  \n",
    " \t  \n",
    " \tdef \\_\\_init\\_\\_(self):  \n",
    "     \tself.test\\_results \\= \\[\\]  \n",
    " \t  \n",
    " \tdef record\\_test\\_run(self, test\\_name: str, users: int, duration: int,  \n",
    "                    \tavg\\_response\\_time: float, failure\\_rate: float,  \n",
    "                    \trps: float, notes: str \\= \"\"):  \n",
    "     \t\"\"\"Record the results of a load test run.\"\"\"  \n",
    "     \t  \n",
    "     \tresult \\= {  \n",
    "         \t'timestamp': datetime.now().isoformat(),  \n",
    "         \t'test\\_name': test\\_name,  \n",
    "         \t'concurrent\\_users': users,  \n",
    "         \t'duration\\_minutes': duration,  \n",
    "         \t'avg\\_response\\_time': avg\\_response\\_time,  \n",
    "         \t'failure\\_rate\\_percent': failure\\_rate,  \n",
    "         \t'requests\\_per\\_second': rps,  \n",
    "         \t'notes': notes  \n",
    "     \t}  \n",
    "     \t  \n",
    "     \tself.test\\_results.append(result)  \n",
    "     \tprint(f\"📊 Recorded test result: {test\\_name} with {users} users\")  \n",
    " \t  \n",
    " \tdef generate\\_performance\\_report(self, filename: str \\= None):  \n",
    "     \t\"\"\"Generate a comprehensive performance report.\"\"\"  \n",
    "     \t  \n",
    "     \tif not filename:  \n",
    "         \ttimestamp \\= datetime.now().strftime(\"%Y%m%d\\_%H%M%S\")  \n",
    "         \tfilename \\= f\"load\\_test\\_report\\_{timestamp}.csv\"  \n",
    "     \t  \n",
    "     \twith open(filename, 'w', newline='') as csvfile:  \n",
    "         \tfieldnames \\= \\[  \n",
    "             \t'timestamp', 'test\\_name', 'concurrent\\_users', 'duration\\_minutes',  \n",
    "             \t'avg\\_response\\_time', 'failure\\_rate\\_percent', 'requests\\_per\\_second', 'notes'  \n",
    "         \t\\]  \n",
    "         \t  \n",
    "         \twriter \\= csv.DictWriter(csvfile, fieldnames=fieldnames)  \n",
    "         \twriter.writeheader()  \n",
    "         \t  \n",
    "         \tfor result in self.test\\_results:  \n",
    "             \twriter.writerow(result)  \n",
    "     \t  \n",
    "     \tprint(f\"📈 Performance report saved to: {filename}\")  \n",
    "     \t  \n",
    "     \t\\# Generate summary statistics  \n",
    "     \tif self.test\\_results:  \n",
    "         \ttotal\\_tests \\= len(self.test\\_results)  \n",
    "         \tavg\\_response\\_time \\= sum(r\\['avg\\_response\\_time'\\] for r in self.test\\_results) / total\\_tests  \n",
    "         \tmax\\_users\\_tested \\= max(r\\['concurrent\\_users'\\] for r in self.test\\_results)  \n",
    "         \tavg\\_failure\\_rate \\= sum(r\\['failure\\_rate\\_percent'\\] for r in self.test\\_results) / total\\_tests  \n",
    "         \t  \n",
    "         \tprint(f\"\\\\n📊 LOAD TEST SUMMARY\")  \n",
    "         \tprint(f\"Total test runs: {total\\_tests}\")  \n",
    "         \tprint(f\"Maximum concurrent users tested: {max\\_users\\_tested}\")  \n",
    "         \tprint(f\"Average response time across all tests: {avg\\_response\\_time:.2f}s\")  \n",
    "         \tprint(f\"Average failure rate: {avg\\_failure\\_rate:.2f}%\")  \n",
    " \t  \n",
    " \tdef recommend\\_production\\_settings(self):  \n",
    "     \t\"\"\"Analyze results and recommend production settings.\"\"\"  \n",
    "     \t  \n",
    "     \tif not self.test\\_results:  \n",
    "         \tprint(\"❌ No test results available for analysis\")  \n",
    "         \treturn  \n",
    "     \t  \n",
    "     \t\\# Find the highest load test with acceptable performance  \n",
    "     \tacceptable\\_tests \\= \\[  \n",
    "         \tr for r in self.test\\_results  \n",
    "         \tif r\\['failure\\_rate\\_percent'\\] \\<= 5.0 and r\\['avg\\_response\\_time'\\] \\<= 10.0  \n",
    "     \t\\]  \n",
    "     \t  \n",
    "     \tif acceptable\\_tests:  \n",
    "         \tbest\\_test \\= max(acceptable\\_tests, key=lambda x: x\\['concurrent\\_users'\\])  \n",
    "         \t  \n",
    "         \tprint(f\"\\\\n💡 PRODUCTION RECOMMENDATIONS\")  \n",
    "         \tprint(f\"Recommended max concurrent users: {best\\_test\\['concurrent\\_users'\\]}\")  \n",
    "         \tprint(f\"Expected average response time: {best\\_test\\['avg\\_response\\_time'\\]:.2f}s\")  \n",
    "         \tprint(f\"Expected failure rate: {best\\_test\\['failure\\_rate\\_percent'\\]:.2f}%\")  \n",
    "         \tprint(f\"Expected throughput: {best\\_test\\['requests\\_per\\_second'\\]:.1f} RPS\")  \n",
    "         \t  \n",
    "         \t\\# Calculate cost estimates  \n",
    "         \tdaily\\_requests \\= best\\_test\\['requests\\_per\\_second'\\] \\* 86400  \\# Requests per day  \n",
    "         \tprint(f\"\\\\nEstimated daily request volume: {daily\\_requests:,.0f} requests\")  \n",
    "         \t  \n",
    "     \telse:  \n",
    "         \tprint(\"⚠️ No test runs met acceptable performance criteria\")  \n",
    "         \tprint(\"Consider optimizing your system before production deployment\")\n",
    "\n",
    " \\# Example usage in your load testing workflow  \n",
    " reporter \\= LoadTestReporter()\n",
    "\n",
    " \\# After each test run, record the results  \n",
    " \\# reporter.record\\_test\\_run(\"Light Load\", 10, 3, 1.5, 0.2, 15.3, \"Baseline test\")  \n",
    " \\# reporter.record\\_test\\_run(\"Heavy Load\", 50, 10, 3.2, 2.1, 45.7, \"Peak traffic simulation\")\n",
    "\n",
    " \\# Generate final report  \n",
    " \\# reporter.generate\\_performance\\_report()  \n",
    " \\# reporter.recommend\\_production\\_settings()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a0b95a-c540-412e-9bd6-f96d8eb0469c",
   "metadata": {},
   "source": [
    "**Production Readiness Checklist**\n",
    "\n",
    "Use this checklist to ensure your DeepSeek reasoning agent is ready for production based on your load testing results:\n",
    "\n",
    "**Performance Criteria**\n",
    "\n",
    "**Response Time Targets**:\n",
    "\n",
    "·       \\[ \\] 95th percentile response time under 5 seconds for simple queries\n",
    "\n",
    "·       \\[ \\] 95th percentile response time under 15 seconds for complex reasoning tasks\n",
    "\n",
    "·       \\[ \\] Average response time under 3 seconds across all query types\n",
    "\n",
    "**Reliability Targets**:\n",
    "\n",
    "·       \\[ \\] Failure rate below 1% under normal load\n",
    "\n",
    "·       \\[ \\] Failure rate below 5% under peak load\n",
    "\n",
    "·       \\[ \\] System recovers gracefully from rate limiting\n",
    "\n",
    "**Scalability Targets**:\n",
    "\n",
    "·       \\[ \\] Maintains performance with 50+ concurrent users\n",
    "\n",
    "·       \\[ \\] Handles traffic spikes without service degradation\n",
    "\n",
    "·       \\[ \\] Response times increase linearly (not exponentially) with load\n",
    "\n",
    "**Cost and Resource Planning**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf112c35-c91d-42f0-85b9-ce9ae6b6521d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate\\_production\\_costs(daily\\_requests: int, avg\\_tokens\\_per\\_request: int,  \n",
    "                               token\\_cost\\_per\\_1000: float \\= 0.002):  \n",
    " \t\"\"\"  \n",
    " \tCalculate estimated production costs based on load testing data.  \n",
    " \t\"\"\"  \n",
    " \t  \n",
    " \tdaily\\_tokens \\= daily\\_requests \\* avg\\_tokens\\_per\\_request  \n",
    " \tdaily\\_cost \\= (daily\\_tokens / 1000\\) \\* token\\_cost\\_per\\_1000  \n",
    " \tmonthly\\_cost \\= daily\\_cost \\* 30  \n",
    " \t  \n",
    " \tprint(f\"💰 PRODUCTION COST ESTIMATES\")  \n",
    " \tprint(f\"Daily requests: {daily\\_requests:,}\")  \n",
    " \tprint(f\"Daily tokens: {daily\\_tokens:,}\")  \n",
    " \tprint(f\"Daily cost: ${daily\\_cost:.2f}\")  \n",
    " \tprint(f\"Monthly cost: ${monthly\\_cost:.2f}\")  \n",
    " \tprint(f\"Annual cost: ${monthly\\_cost \\* 12:.2f}\")  \n",
    " \t  \n",
    " \treturn {  \n",
    "     \t'daily\\_cost': daily\\_cost,  \n",
    "     \t'monthly\\_cost': monthly\\_cost,  \n",
    "     \t'annual\\_cost': monthly\\_cost \\* 12  \n",
    " \t}\n",
    "\n",
    " \\# Example calculation based on load test results  \n",
    " \\# costs \\= calculate\\_production\\_costs(  \n",
    " \\# \tdaily\\_requests=10000,  \n",
    " \\# \tavg\\_tokens\\_per\\_request=500,  \n",
    " \\# \ttoken\\_cost\\_per\\_1000=0.002  \n",
    " \\# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09256585-d221-4f8b-a7d2-886757428f56",
   "metadata": {},
   "source": [
    "**Summary and Next Steps**\n",
    "\n",
    "Load testing with Locust provides invaluable insights into your DeepSeek reasoning agent's production readiness. The comprehensive testing scenarios you've implemented reveal critical performance characteristics that manual testing simply cannot uncover.\n",
    "\n",
    "Key insights from your load testing efforts include:\n",
    "\n",
    "**Performance Baselines**: You now understand how response times change as concurrent users increase, helping you set realistic performance expectations.\n",
    "\n",
    "**Breaking Points**: You've identified the traffic levels where your system begins to show stress, allowing you to plan capacity accordingly.\n",
    "\n",
    "**Cost Projections**: Real load data helps you accurately estimate operational costs at different usage levels.\n",
    "\n",
    "**User Experience Impact**: You understand how different query types and complexity levels affect user experience under load.\n",
    "\n",
    "Remember that load testing is not a one-time activity. As you optimize your reasoning agent, add new features, or change infrastructure, regular load testing ensures continued production readiness. The testing framework you've built can be easily adapted and extended as your system evolves.\n",
    "\n",
    "Your next steps should include:\n",
    "\n",
    "1\\.   \t**Baseline Documentation**: Record your current performance baselines for future comparison\n",
    "\n",
    "2\\.   \t**Monitoring Setup**: Implement production monitoring that tracks the same metrics you tested\n",
    "\n",
    "3\\.   \t**Capacity Planning**: Use your load test data to plan infrastructure and API rate limits\n",
    "\n",
    "4\\.   \t**Performance Optimization**: Address any performance bottlenecks revealed by testing\n",
    "\n",
    "5\\.   \t**Regular Testing Schedule**: Establish ongoing load testing as part of your development cycle\n",
    "\n",
    "The insights you've gained from load testing will guide not just your immediate deployment decisions, but your entire AI strategy going forward. You now have concrete data about how reasoning capabilities perform under real-world conditions, enabling confident, data-driven decisions about your production deployment.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
