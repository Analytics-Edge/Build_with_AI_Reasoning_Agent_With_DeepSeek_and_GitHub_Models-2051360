{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c16fad7e-240c-435c-92b3-2f0b2238ccd9",
   "metadata": {},
   "source": [
    "Here's some fantastic news that will make your development life so much easier‚Äîyou don't need any complicated cloud SDKs, proprietary libraries, or vendor-specific tools to work with DeepSeek\\! Everything you need can be accomplished with standard Python libraries that you probably already know and love.\n",
    "\n",
    "This approach keeps your development environment lean, clean, and completely vendor-agnostic. No more wrestling with complex SDK installations, version conflicts, or being locked into a specific cloud provider's ecosystem. You maintain complete control and flexibility over your development stack while building powerful AI applications that can run anywhere.\n",
    "\n",
    "**Understanding the Simple Integration Approach**\n",
    "\n",
    "The beauty of working with DeepSeek lies in its simplicity. Unlike many AI services that require you to install heavy SDKs, learn vendor-specific APIs, or deal with complex authentication systems, DeepSeek works with standard web technologies that every developer understands: HTTP requests and JSON responses.\n",
    "\n",
    "This means you can integrate DeepSeek into your applications using the same techniques you'd use to work with any web API. Whether you're building a simple script or a complex enterprise application, the integration remains straightforward and predictable.\n",
    "\n",
    "**Setting Up Basic HTTP Communication**\n",
    "\n",
    "Let's start with the most fundamental approach‚Äîmaking direct HTTP requests to the DeepSeek API. This method gives you complete control over every aspect of the communication and helps you understand exactly how the integration works.\n",
    "\n",
    "**Installing Required Dependencies**\n",
    "\n",
    "First, you'll need to ensure you have the requests library installed. This is Python's most popular library for making HTTP requests, and it's likely already available in your environment. However, let's make sure it's installed and up to date.\n",
    "\n",
    "In your terminal or command prompt within your development environment, run this command:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f7cb3e-3e5b-4271-8e33-5860252b58ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install requests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1393ff0-31df-461a-a33a-1cb2f44a234f",
   "metadata": {},
   "source": [
    "You'll see output showing the installation progress. If the library is already installed, you'll see a message indicating that the requirement is already satisfied.\n",
    "\n",
    "**Creating Your Basic API Client**\n",
    "\n",
    "Now let's create a simple but robust function to communicate with the DeepSeek API. In your Python script, add this comprehensive API client function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de394384-ea1e-4290-9f9f-b84406b73f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests  \n",
    " import json  \n",
    " import time\n",
    "\n",
    " def call\\_deepseek\\_api(prompt, config):  \n",
    " \t\"\"\"  \n",
    " \tMake a direct API call to DeepSeek using standard HTTP requests.  \n",
    " \tThis function handles the complete request/response cycle.  \n",
    " \t\"\"\"  \n",
    " \t  \n",
    " \t\\# Set up the request headers  \n",
    " \t\\# These tell the API what format we're sending and provide authentication  \n",
    " \theaders \\= {  \n",
    "     \t\"Content-Type\": \"application/json\",  \n",
    "     \t\"Authorization\": f\"Bearer {config\\['api\\_key'\\]}\"  \n",
    " \t}  \n",
    " \t  \n",
    " \t\\# Create the request payload with all necessary parameters  \n",
    " \tpayload \\= {  \n",
    "     \t\"model\": config\\[\"model\"\\],  \n",
    "     \t\"messages\": \\[{\"role\": \"user\", \"content\": prompt}\\],  \n",
    "     \t\"temperature\": config\\[\"temperature\"\\],  \n",
    "     \t\"max\\_tokens\": config\\[\"max\\_tokens\"\\],  \n",
    "     \t\"reasoning\\_steps\": config.get(\"reasoning\\_steps\", True)  \n",
    " \t}  \n",
    " \t  \n",
    " \ttry:  \n",
    "     \t\\# Make the HTTP POST request to the DeepSeek API  \n",
    "     \tprint(f\"üîÑ Sending request to DeepSeek API...\")  \n",
    "     \tresponse \\= requests.post(  \n",
    "             f\"{config\\['base\\_url'\\]}/chat/completions\",  \n",
    "         \theaders=headers,  \n",
    "         \tjson=payload,  \n",
    "         \ttimeout=30  \\# 30 second timeout to prevent hanging  \n",
    "     \t)  \n",
    "     \t  \n",
    "     \t\\# Check if the request was successful  \n",
    "     \tif response.status\\_code \\== 200:  \n",
    "         \tprint(\"‚úÖ API request successful\")  \n",
    "         \treturn response.json()  \n",
    "     \telse:  \n",
    "         \tprint(f\"‚ùå API request failed with status code: {response.status\\_code}\")  \n",
    "         \tprint(f\"Error response: {response.text}\")  \n",
    "         \treturn None  \n",
    "         \t  \n",
    " \texcept requests.exceptions.Timeout:  \n",
    "     \tprint(\"‚ùå Request timed out after 30 seconds\")  \n",
    "     \treturn None  \n",
    " \texcept requests.exceptions.RequestException as e:  \n",
    "     \tprint(f\"‚ùå Request failed: {str(e)}\")  \n",
    "     \treturn None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04b58d2-7dd2-4a17-90ab-5d522a7ab7bf",
   "metadata": {},
   "source": [
    "Let's break down what this function does step by step:\n",
    "\n",
    "**Headers Setup**: The headers dictionary contains two crucial pieces of information. \"Content-Type\": \"application/json\" tells the API that you're sending data in JSON format. \"Authorization\": f\"Bearer {config\\['api\\_key'\\]}\" provides your API key for authentication using the standard Bearer token format.\n",
    "\n",
    "**Payload Construction**: The payload dictionary contains all the parameters that DeepSeek needs to process your request. It includes your prompt wrapped in a messages array (following the standard chat completion format), along with all the configuration parameters you set up previously.\n",
    "\n",
    "**HTTP Request**: The requests.post() call sends your data to DeepSeek's API endpoint. The timeout=30 parameter ensures that if the API doesn't respond within 30 seconds, your code won't hang indefinitely.\n",
    "\n",
    "**Error Handling**: The try/except block catches common network issues like timeouts or connection problems, providing clear error messages to help you troubleshoot any problems.\n",
    "\n",
    "**Testing Your API Integration**\n",
    "\n",
    "Let's create a simple test function to verify that your API integration is working correctly:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44042d8-a925-4260-b6f3-ed45f1c11d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test\\_api\\_integration(config):  \n",
    " \t\"\"\"  \n",
    " \tTest the DeepSeek API integration with a simple reasoning task.  \n",
    " \t\"\"\"  \n",
    " \tprint(\"üß™ Testing DeepSeek API integration...\")  \n",
    " \t  \n",
    " \t\\# Simple test prompt that should trigger reasoning  \n",
    " \ttest\\_prompt \\= \"If a train travels 60 miles per hour for 2.5 hours, how far does it travel? Please show your reasoning steps.\"  \n",
    " \t  \n",
    " \t\\# Make the API call  \n",
    " \tresult \\= call\\_deepseek\\_api(test\\_prompt, config)  \n",
    " \t  \n",
    " \tif result:  \n",
    "     \tprint(\"‚úÖ API integration test successful\\!\")  \n",
    "     \tprint(\"\\\\nüìã Response preview:\")  \n",
    "     \t  \n",
    "     \t\\# Extract and display the response content  \n",
    "     \tif 'choices' in result and len(result\\['choices'\\]) \\> 0:  \n",
    "         \tcontent \\= result\\['choices'\\]\\[0\\]\\['message'\\]\\['content'\\]  \n",
    "         \tprint(content\\[:200\\] \\+ \"...\" if len(content) \\> 200 else content)  \n",
    "     \t  \n",
    "     \t\\# Display usage information if available  \n",
    "     \tif 'usage' in result:  \n",
    "         \tprint(f\"\\\\nüìä Token usage: {result\\['usage'\\]\\['total\\_tokens'\\]} tokens\")  \n",
    " \telse:  \n",
    "     \tprint(\"‚ùå API integration test failed\")  \n",
    "     \tprint(\"Please check your configuration and API key\")\n",
    "\n",
    " \\# Test your integration (assuming you have your config from the previous chapter)  \n",
    " \\# test\\_api\\_integration(deepseek\\_config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196fd2e4-0ece-4d64-8460-f640f7b96122",
   "metadata": {},
   "source": [
    "When you run this test function, you'll see console output showing the progress of your API call. If everything is set up correctly, you'll see a successful response with DeepSeek's reasoning about the math problem.\n",
    "\n",
    "**Advanced Integration with PraisonAI Framework**\n",
    "\n",
    "While direct HTTP requests give you maximum control, you might prefer working with a higher-level framework that handles many of the technical details automatically. The PraisonAI framework provides an excellent wrapper around AI model APIs while maintaining simplicity and flexibility.\n",
    "\n",
    "**Setting Up PraisonAI Integration**\n",
    "\n",
    "If you haven't already installed PraisonAI in your environment, you can add it with this command:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f821247-6e4a-4eaf-ab4d-c594080fb1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install praisonaiagents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fcda94-378d-4333-bb9a-f6917f3b621a",
   "metadata": {},
   "source": [
    "Once installed, integrating DeepSeek becomes remarkably simple. Here's how to create a DeepSeek-powered agent using PraisonAI:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8a7930-c08d-4e37-8718-f3d4245f7d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from praisonaiagents import Agent\n",
    "\n",
    " def create\\_deepseek\\_agent(config):  \n",
    " \t\"\"\"  \n",
    " \tCreate a PraisonAI agent configured to use DeepSeek's reasoning capabilities.  \n",
    " \t\"\"\"  \n",
    " \t  \n",
    " \t\\# Create the agent with DeepSeek configuration  \n",
    " \tagent \\= Agent(  \n",
    "     \trole=\"Reasoning Specialist\",  \n",
    "     \tgoal=\"Provide clear, step-by-step analysis and solutions\",  \n",
    "     \tbackstory=\"An expert at transparent reasoning who always shows their thinking process\",  \n",
    "     \tllm\\_config=config  \\# Your DeepSeek configuration from the previous chapter  \n",
    " \t)  \n",
    " \t  \n",
    " \tprint(\"‚úÖ DeepSeek reasoning agent created successfully\\!\")  \n",
    " \treturn agent\n",
    "\n",
    " def test\\_praisonai\\_integration(agent):  \n",
    " \t\"\"\"  \n",
    " \tTest the PraisonAI integration with a reasoning task.  \n",
    " \t\"\"\"  \n",
    " \tprint(\"üß™ Testing PraisonAI integration with DeepSeek...\")  \n",
    " \t  \n",
    " \ttest\\_prompt \\= \"A company's revenue increased by 25% in Q1 and then decreased by 15% in Q2. If the original revenue was $100,000, what's the final revenue after Q2? Show your reasoning.\"  \n",
    " \t  \n",
    " \ttry:  \n",
    "     \t\\# Use the agent to process the prompt  \n",
    "     \tresponse \\= agent.execute\\_task(test\\_prompt)  \n",
    "     \t  \n",
    "     \tprint(\"‚úÖ PraisonAI integration successful\\!\")  \n",
    "     \tprint(f\"\\\\nüìã Agent response:\\\\n{response}\")  \n",
    "     \t  \n",
    " \texcept Exception as e:  \n",
    "     \tprint(f\"‚ùå PraisonAI integration failed: {str(e)}\")\n",
    "\n",
    " \\# Example usage:  \n",
    " \\# deepseek\\_agent \\= create\\_deepseek\\_agent(deepseek\\_config)  \n",
    " \\# test\\_praisonai\\_integration(deepseek\\_agent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef151738-b3b6-4bfa-95ee-bc014662ba63",
   "metadata": {},
   "source": [
    "The PraisonAI approach offers several advantages:\n",
    "\n",
    "**Simplified Interface**: You don't need to worry about HTTP headers, request formatting, or response parsing. The framework handles all of this automatically.\n",
    "\n",
    "**Built-in Error Handling**: PraisonAI includes robust error handling and retry logic, making your applications more reliable.\n",
    "\n",
    "**Agent Abstraction**: The agent concept makes it easy to create specialized AI assistants with specific roles and capabilities.\n",
    "\n",
    "**Creating a Flexible Integration Layer**\n",
    "\n",
    "For production applications, you'll want to create a flexible integration layer that can switch between different approaches as needed. Here's a comprehensive integration class that supports both direct API calls and framework integration:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87b30f6-b0af-40c3-84f6-a3e6f578a8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests  \n",
    " import json  \n",
    " from typing import Dict, Optional, Union\n",
    "\n",
    " class DeepSeekIntegration:  \n",
    " \t\"\"\"  \n",
    " \tA flexible integration layer for DeepSeek API that supports multiple approaches.  \n",
    " \t\"\"\"  \n",
    " \t  \n",
    " \tdef \\_\\_init\\_\\_(self, config: Dict):  \n",
    "     \t\"\"\"Initialize the integration with configuration.\"\"\"  \n",
    "     \tself.config \\= config  \n",
    "     \tself.validate\\_config()  \n",
    "     \t  \n",
    " \tdef validate\\_config(self):  \n",
    "     \t\"\"\"Validate the configuration before use.\"\"\"  \n",
    "     \trequired\\_fields \\= \\[\"api\\_key\", \"base\\_url\", \"model\"\\]  \n",
    "     \tfor field in required\\_fields:  \n",
    "         \tif not self.config.get(field):  \n",
    "             \traise ValueError(f\"Missing required configuration field: {field}\")  \n",
    " \t  \n",
    " \tdef make\\_direct\\_request(self, prompt: str, \\*\\*kwargs) \\-\\> Optional\\[Dict\\]:  \n",
    "     \t\"\"\"  \n",
    "     \tMake a direct HTTP request to the DeepSeek API.  \n",
    "     \tAdditional parameters can be passed via kwargs.  \n",
    "     \t\"\"\"  \n",
    "     \t  \n",
    "     \t\\# Merge any additional parameters with base config  \n",
    "     \trequest\\_config \\= self.config.copy()  \n",
    "     \trequest\\_config.update(kwargs)  \n",
    "     \t  \n",
    "     \theaders \\= {  \n",
    "         \t\"Content-Type\": \"application/json\",  \n",
    "         \t\"Authorization\": f\"Bearer {request\\_config\\['api\\_key'\\]}\"  \n",
    "     \t}  \n",
    "     \t  \n",
    "     \tpayload \\= {  \n",
    "         \t\"model\": request\\_config\\[\"model\"\\],  \n",
    "         \t\"messages\": \\[{\"role\": \"user\", \"content\": prompt}\\],  \n",
    "         \t\"temperature\": request\\_config.get(\"temperature\", 0.1),  \n",
    "         \t\"max\\_tokens\": request\\_config.get(\"max\\_tokens\", 3000),  \n",
    "         \t\"reasoning\\_steps\": request\\_config.get(\"reasoning\\_steps\", True)  \n",
    "     \t}  \n",
    "     \t  \n",
    "     \ttry:  \n",
    "         \tprint(f\"üîÑ Making direct API request...\")  \n",
    "         \tresponse \\= requests.post(  \n",
    "                 f\"{request\\_config\\['base\\_url'\\]}/chat/completions\",  \n",
    "             \theaders=headers,  \n",
    "             \tjson=payload,  \n",
    "             \ttimeout=30  \n",
    "         \t)  \n",
    "         \t  \n",
    "         \tif response.status\\_code \\== 200:  \n",
    "             \tprint(\"‚úÖ Direct request successful\")  \n",
    "             \treturn response.json()  \n",
    "         \telse:  \n",
    "             \tprint(f\"‚ùå Request failed: {response.status\\_code}\")  \n",
    "             \treturn None  \n",
    "             \t  \n",
    "     \texcept Exception as e:  \n",
    "         \tprint(f\"‚ùå Request error: {str(e)}\")  \n",
    "         \treturn None  \n",
    " \t  \n",
    " \tdef create\\_agent(self, role: str \\= \"AI Assistant\",  \n",
    "                 \tgoal: str \\= \"Provide helpful responses\",  \n",
    "                 \tbackstory: str \\= \"A helpful AI assistant\"):  \n",
    "     \t\"\"\"  \n",
    "     \tCreate a PraisonAI agent with the current configuration.  \n",
    "     \t\"\"\"  \n",
    "     \ttry:  \n",
    "         \tfrom praisonaiagents import Agent  \n",
    "         \t  \n",
    "         \tagent \\= Agent(  \n",
    "             \trole=role,  \n",
    "             \tgoal=goal,  \n",
    "             \tbackstory=backstory,  \n",
    "             \tllm\\_config=self.config  \n",
    "         \t)  \n",
    "         \t  \n",
    "         \tprint(f\"‚úÖ Created agent: {role}\")  \n",
    "         \treturn agent  \n",
    "         \t  \n",
    "     \texcept ImportError:  \n",
    "         \tprint(\"‚ùå PraisonAI not available. Install with: pip install praisonaiagents\")  \n",
    "         \treturn None  \n",
    "     \texcept Exception as e:  \n",
    "         \tprint(f\"‚ùå Agent creation failed: {str(e)}\")  \n",
    "         \treturn None  \n",
    " \t  \n",
    " \tdef ask(self, prompt: str, method: str \\= \"direct\", \\*\\*kwargs) \\-\\> Optional\\[str\\]:  \n",
    "     \t\"\"\"  \n",
    "     \tAsk a question using the specified method (direct or agent).  \n",
    "     \t\"\"\"  \n",
    "     \tif method \\== \"direct\":  \n",
    "         \tresult \\= self.make\\_direct\\_request(prompt, \\*\\*kwargs)  \n",
    "         \tif result and 'choices' in result:  \n",
    "             \treturn result\\['choices'\\]\\['message'\\]\\['content'\\]  \n",
    "         \treturn None  \n",
    "         \t  \n",
    "     \telif method \\== \"agent\":  \n",
    "         \tagent \\= self.create\\_agent(\\*\\*kwargs)  \n",
    "         \tif agent:  \n",
    "             \ttry:  \n",
    "                 \treturn agent.execute\\_task(prompt)  \n",
    "             \texcept Exception as e:  \n",
    "                 \tprint(f\"‚ùå Agent execution failed: {str(e)}\")  \n",
    "                 \treturn None  \n",
    "         \treturn None  \n",
    "         \t  \n",
    "     \telse:  \n",
    "         \tprint(f\"‚ùå Unknown method: {method}. Use 'direct' or 'agent'\")  \n",
    "         \treturn None  \n",
    " \t  \n",
    " \tdef benchmark\\_methods(self, test\\_prompt: str):  \n",
    "     \t\"\"\"  \n",
    "     \tCompare the performance of different integration methods.  \n",
    "     \t\"\"\"  \n",
    "     \tprint(\"üèÅ Benchmarking integration methods...\")  \n",
    "     \t  \n",
    "     \tresults \\= {}  \n",
    "     \t  \n",
    "     \t\\# Test direct method  \n",
    "     \tprint(\"\\\\nüìä Testing direct API method...\")  \n",
    "     \tstart\\_time \\= time.time()  \n",
    "     \tdirect\\_result \\= self.ask(test\\_prompt, method=\"direct\")  \n",
    "     \tdirect\\_time \\= time.time() \\- start\\_time  \n",
    "     \t  \n",
    "     \tresults\\['direct'\\] \\= {  \n",
    "         \t'time': direct\\_time,  \n",
    "         \t'success': direct\\_result is not None,  \n",
    "         \t'response\\_length': len(direct\\_result) if direct\\_result else 0  \n",
    "     \t}  \n",
    "     \t  \n",
    "     \t\\# Test agent method  \n",
    "     \tprint(\"\\\\nüìä Testing PraisonAI agent method...\")  \n",
    "     \tstart\\_time \\= time.time()  \n",
    "     \tagent\\_result \\= self.ask(test\\_prompt, method=\"agent\")  \n",
    "     \tagent\\_time \\= time.time() \\- start\\_time  \n",
    "     \t  \n",
    "     \tresults\\['agent'\\] \\= {  \n",
    "         \t'time': agent\\_time,  \n",
    "         \t'success': agent\\_result is not None,  \n",
    "         \t'response\\_length': len(agent\\_result) if agent\\_result else 0  \n",
    "     \t}  \n",
    "     \t  \n",
    "     \t\\# Display benchmark results  \n",
    "     \tprint(\"\\\\nüìà Benchmark Results:\")  \n",
    "     \tfor method, data in results.items():  \n",
    "         \tstatus \\= \"‚úÖ Success\" if data\\['success'\\] else \"‚ùå Failed\"  \n",
    "         \tprint(f\"{method.title()} method: {status}, {data\\['time'\\]:.2f}s, {data\\['response\\_length'\\]} chars\")  \n",
    "     \t  \n",
    "     \treturn results\n",
    "\n",
    " \\# Example usage  \n",
    " def demonstrate\\_integration\\_flexibility():  \n",
    " \t\"\"\"  \n",
    " \tDemonstrate the flexibility of the integration layer.  \n",
    " \t\"\"\"  \n",
    " \t\\# Assuming you have your config from previous chapters  \n",
    " \ttry:  \n",
    "     \t\\# Create the integration instance  \n",
    "     \tintegration \\= DeepSeekIntegration(deepseek\\_config)  \n",
    "     \t  \n",
    "     \t\\# Test prompt  \n",
    "     \ttest\\_prompt \\= \"What are the key advantages of using renewable energy sources?\"  \n",
    "     \t  \n",
    "     \tprint(\"üîÑ Demonstrating integration flexibility...\\\\n\")  \n",
    "     \t  \n",
    "     \t\\# Method 1: Direct API call  \n",
    "     \tprint(\"Method 1: Direct API Call\")  \n",
    "     \tdirect\\_response \\= integration.ask(test\\_prompt, method=\"direct\")  \n",
    "     \tif direct\\_response:  \n",
    "         \tprint(f\"Response: {direct\\_response\\[:100\\]}...\")  \n",
    "     \t  \n",
    "     \tprint(\"\\\\n\" \\+ \"=\"\\*50 \\+ \"\\\\n\")  \n",
    "     \t  \n",
    "     \t\\# Method 2: Agent-based approach  \n",
    "     \tprint(\"Method 2: Agent-based Approach\")  \n",
    "     \tagent\\_response \\= integration.ask(  \n",
    "         \ttest\\_prompt,  \n",
    "     \t    method=\"agent\",  \n",
    "         \trole=\"Environmental Expert\",  \n",
    "         \tgoal=\"Provide comprehensive information about renewable energy\"  \n",
    "     \t)  \n",
    "     \tif agent\\_response:  \n",
    "         \tprint(f\"Response: {agent\\_response\\[:100\\]}...\")  \n",
    "     \t  \n",
    "     \tprint(\"\\\\n\" \\+ \"=\"\\*50 \\+ \"\\\\n\")  \n",
    "     \t  \n",
    "     \t\\# Method 3: Benchmark comparison  \n",
    "         integration.benchmark\\_methods(test\\_prompt)  \n",
    "     \t  \n",
    " \texcept NameError:  \n",
    "     \tprint(\"‚ùå Please ensure your deepseek\\_config is defined from previous chapters\")\n",
    "\n",
    " \\# Uncomment to run the demonstration  \n",
    " \\# demonstrate\\_integration\\_flexibility()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a07c37-c64a-4620-9871-e753c069692c",
   "metadata": {},
   "source": [
    "**Understanding the Benefits of This Approach**\n",
    "\n",
    "This lightweight, standards-based approach to DeepSeek integration brings multiple significant benefits to your development workflow that will become more apparent as your projects grow in complexity.\n",
    "\n",
    "**Debugging Simplicity**\n",
    "\n",
    "When something goes wrong with your AI integration, you can easily diagnose the problem. Since you're working with standard HTTP requests and JSON responses, you can:\n",
    "\n",
    "¬∑       Log the exact requests being sent to inspect your data\n",
    "\n",
    "¬∑       Examine the raw API responses to understand what's happening\n",
    "\n",
    "¬∑       Use standard web debugging tools to trace network communication\n",
    "\n",
    "¬∑       Create simple test cases that isolate specific issues\n",
    "\n",
    "Here's a simple debugging helper you can add to your integration:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426dda46-3b11-484e-b296-14260a38d618",
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug\\_api\\_call(prompt, config, save\\_to\\_file=True):  \n",
    " \t\"\"\"  \n",
    " \tMake an API call with detailed debugging information.  \n",
    " \t\"\"\"  \n",
    " \tprint(\"üîç Debug mode: Making API call with full logging...\")  \n",
    " \t  \n",
    " \t\\# Log the request details  \n",
    " \tprint(f\"üì§ Request URL: {config\\['base\\_url'\\]}/chat/completions\")  \n",
    " \tprint(f\"üì§ Model: {config\\['model'\\]}\")  \n",
    " \tprint(f\"üì§ Temperature: {config\\['temperature'\\]}\")  \n",
    " \tprint(f\"üì§ Max Tokens: {config\\['max\\_tokens'\\]}\")  \n",
    " \tprint(f\"üì§ Prompt: {prompt\\[:100\\]}...\")  \n",
    " \t  \n",
    " \t\\# Make the call and capture timing  \n",
    " \tstart\\_time \\= time.time()  \n",
    " \tresult \\= call\\_deepseek\\_api(prompt, config)  \n",
    " \tend\\_time \\= time.time()  \n",
    " \t  \n",
    " \tprint(f\"‚è±Ô∏è Request took: {end\\_time \\- start\\_time:.2f} seconds\")  \n",
    " \t  \n",
    " \tif result:  \n",
    "     \tprint(\"üì• Response received successfully\")  \n",
    "     \tif 'usage' in result:  \n",
    "         \tusage \\= result\\['usage'\\]  \n",
    "         \tprint(f\"üìä Tokens used: {usage.get('total\\_tokens', 'unknown')}\")  \n",
    "     \t  \n",
    "     \t\\# Optionally save to file for detailed analysis  \n",
    "     \tif save\\_to\\_file:  \n",
    "         \tdebug\\_filename \\= f\"debug\\_response\\_{int(time.time())}.json\"  \n",
    "         \twith open(debug\\_filename, 'w') as f:  \n",
    "             \tjson.dump(result, f, indent=2)  \n",
    "         \tprint(f\"üíæ Full response saved to: {debug\\_filename}\")  \n",
    " \telse:  \n",
    "     \tprint(\"‚ùå No response received\")  \n",
    " \t  \n",
    " \treturn result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399092a9-bda5-49d4-8a6c-bfe74db54e23",
   "metadata": {},
   "source": [
    "**Testing Made Simple**\n",
    "\n",
    "Testing your AI integration becomes straightforward when you're working with standard web technologies. You can easily create mock responses, unit tests, and integration tests:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f0ccc2-6afd-4ae9-8a4c-225e46f6b78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest  \n",
    " from unittest.mock import Mock, patch\n",
    "\n",
    " class TestDeepSeekIntegration(unittest.TestCase):  \n",
    " \t\"\"\"  \n",
    " \tUnit tests for DeepSeek integration.  \n",
    " \t\"\"\"  \n",
    " \t  \n",
    " \tdef setUp(self):  \n",
    "     \t\"\"\"Set up test configuration.\"\"\"  \n",
    "     \tself.test\\_config \\= {  \n",
    "         \t'api\\_key': 'test\\_key\\_123',  \n",
    "         \t'base\\_url': 'https://api.deepseek.com/v1',  \n",
    "         \t'model': 'deepseek-reasoner',  \n",
    "         \t'temperature': 0.1,  \n",
    "         \t'max\\_tokens': 1000  \n",
    "     \t}  \n",
    " \t  \n",
    " \t@patch('requests.post')  \n",
    " \tdef test\\_successful\\_api\\_call(self, mock\\_post):  \n",
    "     \t\"\"\"Test a successful API call.\"\"\"  \n",
    "     \t\\# Mock a successful response  \n",
    "     \tmock\\_response \\= Mock()  \n",
    "     \tmock\\_response.status\\_code \\= 200  \n",
    "     \tmock\\_response.json.return\\_value \\= {  \n",
    "         \t'choices': \\[{'message': {'content': 'Test response'}}\\],  \n",
    "         \t'usage': {'total\\_tokens': 50}  \n",
    "     \t}  \n",
    "     \tmock\\_post.return\\_value \\= mock\\_response  \n",
    "     \t  \n",
    "     \t\\# Make the call  \n",
    "     \tresult \\= call\\_deepseek\\_api(\"Test prompt\", self.test\\_config)  \n",
    "     \t  \n",
    "         \\# Verify the result  \n",
    "     \tself.assertIsNotNone(result)  \n",
    "     \tself.assertIn('choices', result)  \n",
    "     \t  \n",
    " \t@patch('requests.post')  \n",
    " \tdef test\\_api\\_error\\_handling(self, mock\\_post):  \n",
    "     \t\"\"\"Test API error handling.\"\"\"  \n",
    "     \t\\# Mock a failed response  \n",
    "     \tmock\\_response \\= Mock()  \n",
    "     \tmock\\_response.status\\_code \\= 401  \n",
    "     \tmock\\_response.text \\= \"Unauthorized\"  \n",
    "     \tmock\\_post.return\\_value \\= mock\\_response  \n",
    "     \t  \n",
    "     \t\\# Make the call  \n",
    "     \tresult \\= call\\_deepseek\\_api(\"Test prompt\", self.test\\_config)  \n",
    "     \t  \n",
    "     \t\\# Verify error handling  \n",
    "     \tself.assertIsNone(result)\n",
    "\n",
    " \\# Run tests with: python \\-m pytest test\\_file.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e19fda-7fa6-44d4-8803-6b492caf239a",
   "metadata": {},
   "source": [
    "**Deployment Flexibility**\n",
    "\n",
    "Your code can run anywhere Python runs, without worrying about SDK compatibility or vendor-specific runtime requirements:\n",
    "\n",
    "¬∑       **Local Development**: Run on your laptop or desktop for development and testing\n",
    "\n",
    "¬∑       **Cloud Servers**: Deploy to any cloud provider (AWS, Google Cloud, DigitalOcean, etc.)\n",
    "\n",
    "¬∑       **Containers**: Package in Docker containers without SDK dependencies\n",
    "\n",
    "¬∑       **Serverless Functions**: Run in Lambda, Cloud Functions, or other serverless environments\n",
    "\n",
    "¬∑       **Edge Computing**: Deploy to edge devices or embedded systems\n",
    "\n",
    "**Maintenance Simplicity**\n",
    "\n",
    "You're not dependent on a third-party SDK's update cycle, breaking changes, or deprecation schedules. Your integration code stays stable and predictable over time. When DeepSeek updates their API, you can choose when and how to adapt your code, rather than being forced to upgrade due to SDK changes.\n",
    "\n",
    "**Complete Integration Example**\n",
    "\n",
    "Let's put everything together in a complete example that demonstrates all the integration approaches you've learned:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc08174-1e2d-43da-aacd-69ae3de1fdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests  \n",
    " import json  \n",
    " import time  \n",
    " from typing import Optional, Dict\n",
    "\n",
    " class CompleteDeepSeekIntegration:  \n",
    " \t\"\"\"  \n",
    " \tA complete DeepSeek integration example showcasing all approaches.  \n",
    " \t\"\"\"  \n",
    " \t  \n",
    " \tdef \\_\\_init\\_\\_(self, config: Dict):  \n",
    "     \tself.config \\= config  \n",
    "     \tself.request\\_history \\= \\[\\]  \n",
    " \t  \n",
    " \tdef direct\\_api\\_request(self, prompt: str) \\-\\> Optional\\[Dict\\]:  \n",
    "     \t\"\"\"Direct API integration approach.\"\"\"  \n",
    "     \theaders \\= {  \n",
    "         \t\"Content-Type\": \"application/json\",  \n",
    "         \t\"Authorization\": f\"Bearer {self.config\\['api\\_key'\\]}\"  \n",
    "     \t}  \n",
    "     \t  \n",
    "     \tpayload \\= {  \n",
    "         \t\"model\": self.config\\[\"model\"\\],  \n",
    "         \t\"messages\": \\[{\"role\": \"user\", \"content\": prompt}\\],  \n",
    "         \t\"temperature\": self.config\\[\"temperature\"\\],  \n",
    "         \t\"max\\_tokens\": self.config\\[\"max\\_tokens\"\\],  \n",
    "         \t\"reasoning\\_steps\": self.config.get(\"reasoning\\_steps\", True)  \n",
    "     \t}  \n",
    "     \t  \n",
    "     \ttry:  \n",
    "         \tresponse \\= requests.post(  \n",
    "                 f\"{self.config\\['base\\_url'\\]}/chat/completions\",  \n",
    "           \t  headers=headers,  \n",
    "             \tjson=payload,  \n",
    "             \ttimeout=30  \n",
    "         \t)  \n",
    "         \t  \n",
    "         \t\\# Log the request for analytics  \n",
    "         \tself.request\\_history.append({  \n",
    "             \t'timestamp': time.time(),  \n",
    "             \t'method': 'direct',  \n",
    "             \t'prompt\\_length': len(prompt),  \n",
    "             \t'success': response.status\\_code \\== 200  \n",
    "         \t})  \n",
    "         \t  \n",
    "         \treturn response.json() if response.status\\_code \\== 200 else None  \n",
    "         \t  \n",
    "     \texcept Exception as e:  \n",
    "         \tprint(f\"Direct API error: {e}\")  \n",
    "         \treturn None  \n",
    " \t  \n",
    " \tdef framework\\_request(self, prompt: str, role: str \\= \"AI Assistant\") \\-\\> Optional\\[str\\]:  \n",
    "     \t\"\"\"Framework-based integration approach.\"\"\"  \n",
    "     \ttry:  \n",
    "         \tfrom praisonaiagents import Agent  \n",
    "         \t  \n",
    "         \tagent \\= Agent(  \n",
    "             \trole=role,  \n",
    "             \tgoal=\"Provide clear, helpful responses\",  \n",
    "             \tbackstory=\"A knowledgeable AI assistant\",  \n",
    "             \tllm\\_config=self.config  \n",
    "         \t)  \n",
    "         \t  \n",
    "         \tresult \\= agent.execute\\_task(prompt)  \n",
    "         \t  \n",
    "         \t\\# Log the request  \n",
    "         \tself.request\\_history.append({  \n",
    "             \t'timestamp': time.time(),  \n",
    "             \t'method': 'framework',  \n",
    "             \t'prompt\\_length': len(prompt),  \n",
    "             \t'success': result is not None  \n",
    "         \t})  \n",
    "         \t  \n",
    "         \treturn result  \n",
    "         \t  \n",
    "     \texcept ImportError:  \n",
    "         \tprint(\"PraisonAI not available. Using direct method as fallback.\")  \n",
    "         \tdirect\\_result \\= self.direct\\_api\\_request(prompt)  \n",
    "         \tif direct\\_result and 'choices' in direct\\_result:  \n",
    "             \treturn direct\\_result\\['choices'\\]\\[0\\]\\['message'\\]\\['content'\\]  \n",
    "         \treturn None  \n",
    "     \texcept Exception as e:  \n",
    "         \tprint(f\"Framework error: {e}\")  \n",
    "         \treturn None  \n",
    " \t  \n",
    " \tdef smart\\_request(self, prompt: str, prefer\\_method: str \\= \"auto\") \\-\\> str:  \n",
    "     \t\"\"\"  \n",
    "     \tIntelligent request routing that chooses the best method automatically.  \n",
    "     \t\"\"\"  \n",
    "     \t  \n",
    "     \t\\# Simple heuristic: use framework for complex prompts, direct for simple ones  \n",
    "     \tif prefer\\_method \\== \"auto\":  \n",
    "         \tif len(prompt) \\> 200 or \"analyze\" in prompt.lower() or \"explain\" in prompt.lower():  \n",
    "             \tmethod \\= \"framework\"  \n",
    "         \telse:  \n",
    "             \tmethod \\= \"direct\"  \n",
    "     \telse:  \n",
    "         \tmethod \\= prefer\\_method  \n",
    "     \t  \n",
    "     \tprint(f\"üß† Using {method} method for this request\")  \n",
    "     \t  \n",
    "     \tif method \\== \"framework\":  \n",
    "         \tresult \\= self.framework\\_request(prompt)  \n",
    "         \tif result:  \n",
    "             \treturn result  \n",
    "         \t\\# Fallback to direct if framework fails  \n",
    "         \tprint(\"‚ö†Ô∏è Falling back to direct method\")  \n",
    "     \t  \n",
    "     \t\\# Use direct method  \n",
    "     \tdirect\\_result \\= self.direct\\_api\\_request(prompt)  \n",
    "     \tif direct\\_result and 'choices' in direct\\_result:  \n",
    "         \treturn direct\\_result\\['choices'\\]\\['message'\\]\\['content'\\]  \n",
    "     \t  \n",
    "     \treturn \"Sorry, I couldn't process your request at this time.\"  \n",
    " \t  \n",
    " \tdef get\\_analytics(self) \\-\\> Dict:  \n",
    "     \t\"\"\"Get analytics about integration usage.\"\"\"  \n",
    "     \tif not self.request\\_history:  \n",
    "         \treturn {\"message\": \"No requests made yet\"}  \n",
    "     \t  \n",
    "     \ttotal\\_requests \\= len(self.request\\_history)  \n",
    "     \tsuccessful\\_requests \\= sum(1 for req in self.request\\_history if req\\['success'\\])  \n",
    "     \t  \n",
    "     \tmethod\\_counts \\= {}  \n",
    "     \tfor req in self.request\\_history:  \n",
    "         \tmethod \\= req\\['method'\\]  \n",
    "         \tmethod\\_counts\\[method\\] \\= method\\_counts.get(method, 0\\) \\+ 1  \n",
    "     \t  \n",
    "     \treturn {  \n",
    "         \t\"total\\_requests\": total\\_requests,  \n",
    "             \"successful\\_requests\": successful\\_requests,  \n",
    "         \t\"success\\_rate\": f\"{(successful\\_requests/total\\_requests)\\*100:.1f}%\",  \n",
    "         \t\"method\\_usage\": method\\_counts,  \n",
    "             \"average\\_prompt\\_length\": sum(req\\['prompt\\_length'\\] for req in self.request\\_history) / total\\_requests  \n",
    "     \t}\n",
    "\n",
    " \\# Complete demonstration function  \n",
    " def run\\_complete\\_demo():  \n",
    " \t\"\"\"  \n",
    " \tRun a complete demonstration of all integration approaches.  \n",
    " \t\"\"\"  \n",
    " \tprint(\"üöÄ Starting Complete DeepSeek Integration Demo\\\\n\")  \n",
    " \t  \n",
    " \t\\# Sample configuration (replace with your actual config)  \n",
    " \tdemo\\_config \\= {  \n",
    "     \t\"model\": \"deepseek-reasoner\",  \n",
    "     \t\"api\\_key\": \"your\\_api\\_key\\_here\",  \\# Replace with actual key  \n",
    "     \t\"base\\_url\": \"https://api.deepseek.com/v1\",  \n",
    "     \t\"temperature\": 0.1,  \n",
    "     \t\"max\\_tokens\": 2000,  \n",
    "     \t\"reasoning\\_steps\": True  \n",
    " \t}  \n",
    " \t  \n",
    " \t\\# Create integration instance  \n",
    " \tintegration \\= CompleteDeepSeekIntegration(demo\\_config)  \n",
    " \t  \n",
    " \t\\# Test prompts  \n",
    " \ttest\\_prompts \\= \\[  \n",
    "     \t\"What is 2+2?\",  \\# Simple prompt  \n",
    "     \t\"Analyze the benefits and drawbacks of remote work for companies and employees.\",  \\# Complex prompt  \n",
    "     \t\"Explain quantum computing in simple terms.\"  \\# Medium complexity  \n",
    " \t\\]  \n",
    " \t  \n",
    " \tprint(\"üìù Testing different prompts with smart routing:\\\\n\")  \n",
    " \t  \n",
    " \tfor i, prompt in enumerate(test\\_prompts, 1):  \n",
    "     \tprint(f\"Test {i}: {prompt}\")  \n",
    "     \tresponse \\= integration.smart\\_request(prompt)  \n",
    "     \tprint(f\"Response: {response\\[:150\\]}...\\\\n\")  \n",
    "     \ttime.sleep(1)  \\# Be respectful to the API  \n",
    " \t  \n",
    " \t\\# Display analytics  \n",
    " \tprint(\"üìä Integration Analytics:\")  \n",
    " \tanalytics \\= integration.get\\_analytics()  \n",
    " \tfor key, value in analytics.items():  \n",
    "     \tprint(f\"  {key}: {value}\")\n",
    "\n",
    " \\# Uncomment to run the demo (make sure to set your actual API key first)  \n",
    " \\# run\\_complete\\_demo()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11c49a7-ea21-4eba-9a8a-14cb4b5aa4f3",
   "metadata": {},
   "source": [
    "**Summary and Next Steps**\n",
    "\n",
    "You now have a complete understanding of how to integrate DeepSeek into your applications using multiple approaches, from simple direct HTTP requests to sophisticated framework-based solutions. This lightweight, standards-based approach exemplifies good software engineering practices: minimal dependencies, widely-adopted standards, and clear separation between your application logic and external service integration.\n",
    "\n",
    "The key takeaways from this integration approach are:\n",
    "\n",
    "**Simplicity**: No complex SDKs or vendor-specific libraries required‚Äîjust standard Python and HTTP  \n",
    " **Flexibility**: Your code can run anywhere and adapt to different deployment requirements  \n",
    " **Maintainability**: Standard web technologies make debugging, testing, and long-term maintenance straightforward  \n",
    " **Control**: You maintain complete control over the integration without vendor lock-in\n",
    "\n",
    "Your future self and your teammates will thank you for choosing this clean, maintainable approach to AI integration. In the next section, you'll learn how to build upon this foundation to create sophisticated AI agents that can handle complex reasoning tasks with transparency and reliability.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
